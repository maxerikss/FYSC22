{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainties in python (simple examples)\n",
    "\n",
    "(from the Example in the guides prepared by Dirk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties import ufloat, ufloat_fromstr\n",
    "from uncertainties.umath import *  # sin(), etc.\n",
    "from uncertainties import unumpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Ratio of quantities\n",
    "\n",
    "Determine $R=\\frac{Y(511\\,\\text{keV})}{2Y(1275\\,\\text{keV})}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput data\n",
    "# Y1 -> Y(511keV)\n",
    "# Y2 -> Y(1275keV)\n",
    "Y1 = [ ufloat(203500, sqrt(203500)), # <-- basically Y +/- sqrt(Y)\n",
    "       ufloat(220100, sqrt(220100)), \n",
    "       ufloat(157400, sqrt(157400)), \n",
    "       ufloat(188300, sqrt(188300))]\n",
    "Y2 = [ ufloat(115500, sqrt(115500)), \n",
    "       ufloat(121100, sqrt(121100)), \n",
    "       ufloat( 89100, sqrt( 89100)), \n",
    "       ufloat(107200, sqrt(107200)) ]\n",
    "\n",
    "# turn the python lists into numpy arrays\n",
    "Y1 = np.array(Y1)\n",
    "Y2 = np.array(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple average (function): 0.8878(17)\n"
     ]
    }
   ],
   "source": [
    "def avg_simple(to_be_avg):\n",
    "    \"\"\"\n",
    "    simple average: add the values and divided by the number of values.\n",
    "    \n",
    "    This intends to introduce the benefit of using numpy arrays instead \n",
    "    of coding your own functions always. Sometimes one has to anyway.\n",
    "    \"\"\"\n",
    "    avg = 0\n",
    "    for val in to_be_avg:\n",
    "        avg += val\n",
    "    return avg/len(to_be_avg)\n",
    "\n",
    "print(\"Simple average (function): {:.2uS}\".format(avg_simple(Y1/(2*Y2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted average vs. simple average\n",
    "\n",
    "As we saw from before, the average is a simple mathematical operation that it does not take into account the unceirtainties of each individual quantity\n",
    "\n",
    "$$\n",
    "A = \\frac{\\sum_{i=1}^n X_i}{n}\n",
    "$$\n",
    "\n",
    "the better way to average quantities with unceirtainties is to *weight* each value to be averaged by its weight.\n",
    "\n",
    "$$\n",
    "W_A = \\frac{\\sum_{i=1}^n w_i X_i}{\\sum_{i=1}^n w_i}\n",
    "$$\n",
    "\n",
    "let's see the difference with a numerical example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside = 0.0109+/-0.0006 uSv/h and 96+/-5 uSv/yr\n",
      "outside = 0.0112+/-0.0006 uSv/h and 99+/-5 uSv/yr\n"
     ]
    }
   ],
   "source": [
    "# 53mCo proton emission energies in keV measured with different \n",
    "# setups and experiments ober the years \n",
    "jac1970 = ufloat_fromstr(\"1560(40)\")\n",
    "cer1972 = ufloat_fromstr(\"1590(30)\")\n",
    "she2015 = ufloat_fromstr(\"1558(8)\")\n",
    "kan2010 = ufloat_fromstr(\"1559(7)\")\n",
    "nes2017 = ufloat_fromstr(\"1558.8(17)\")\n",
    "\n",
    "# create the numpy array to be averaged\n",
    "to_be_avg = [jac1970, cer1972, she2015, kan2010, nes2017]\n",
    "\n",
    "def avg_weight(to_be_avg):\n",
    "    \"\"\"\n",
    "    weighted average: add the values and divided by the number of values.\n",
    "    \"\"\"\n",
    "    num = 0\n",
    "    den = 0\n",
    "    for val in to_be_avg:\n",
    "        num += val.n / val.s**2\n",
    "        den +=     1 / val.s**2\n",
    "        \n",
    "    mean = num/den\n",
    "    sigma = np.sqrt( 1 / den )\n",
    "    avg_weight = ufloat( mean, sigma )\n",
    "    return avg_weight\n",
    "\n",
    "#print(\"WA = {:S} keV (weighted)\".format(avg_weight(to_be_avg)))\n",
    "#print(\" A = {:S} keV (simple)\".format(avg_simple(to_be_avg )))\n",
    "\n",
    "inside = [ufloat(0.01, 0.001), \n",
    "          ufloat(0.01, 0.001), \n",
    "          ufloat(0.04, 0.004), \n",
    "          ufloat(0.1, 0.01),\n",
    "          ufloat(0.01, 0.001)]\n",
    "\n",
    "outside = [ufloat(0.01, 0.001), \n",
    "          ufloat(0.01, 0.001), \n",
    "          ufloat(0.01, 0.001), \n",
    "          ufloat(0.05, 0.005),\n",
    "          ufloat(0.02, 0.002)]\n",
    "\n",
    "print(f'inside = {avg_weight(inside)} uSv/h and {avg_weight(inside) * 8765.81277} uSv/yr')\n",
    "print(f'outside = {avg_weight(outside)} uSv/h and {avg_weight(outside) * 8765.81277} uSv/yr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using numpy directly to get averages\n",
    "\n",
    "One can always use `numpy` directly to get those averages. The only drawback is that I do not know how to get the propagation of the uncertainty properly/easily done. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"We can get numpy to do it for us\")\n",
    "values_to_be_avg  = unumpy.nominal_values(to_be_avg) # <-- get the values only\n",
    "weigths_to_be_avg =1/unumpy.std_devs(to_be_avg)**2\n",
    "print(\"weighted average (numpy): {:.5} keV\".format(np.average(values_to_be_avg, weights=weigths_to_be_avg)))\n",
    "print(\"         average (numpy): {:.5} keV\".format(np.average(unumpy.nominal_values(values_to_be_avg))))\n",
    "print()\n",
    "print(\"HOWEVER, I (Pico) currently do not know an easy way to get the weighted uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of an energy calibration\n",
    "\n",
    "Here we also show another way to use values with unceirtanties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties import ufloat_fromstr\n",
    "# Note, no errors reported in the y axis.\n",
    "# BUT we always have the systematic one from the precision. 0.1 in this case.\n",
    "y_i = [\n",
    "    ufloat_fromstr(\"279.2\"),\n",
    "    ufloat_fromstr(\"511.0\"),\n",
    "    ufloat_fromstr(\"1274.5\"),\n",
    "    ufloat_fromstr(\"2614.5\"),\n",
    "]\n",
    "# errors in the x axis from the uncertainty of the fit in the centroid of the peak.\n",
    "x_i = [\n",
    "    ufloat_fromstr(\"107.1(5)\"),\n",
    "    ufloat_fromstr(\"180.1(7)\"),\n",
    "    ufloat_fromstr(\"421.3(11)\"),\n",
    "    ufloat_fromstr(\"841.9(18)\"),\n",
    "]\n",
    "\n",
    "y  = [ i.n for i in y_i ] # n -> nominal value\n",
    "dy = [ i.s for i in y_i ] # s -> standard deviation.\n",
    "\n",
    "x  = [ i.n for i in x_i ] # n -> nominal value\n",
    "dx = [ i.s for i in x_i ] # s -> standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Energy calibration\", fontsize=14, fontweight='bold')\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "ax.set_xlabel(\"channel [a.u.]\")\n",
    "ax.set_ylabel(\"Energy [keV]\")\n",
    "\n",
    "# plot dots\n",
    "plt.scatter(x, y)\n",
    "#plot with error bars. OBS: They are smaller than the scatter dot.\n",
    "plt.errorbar(x, y, xerr=dx, yerr=dy, linestyle=':' )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's so some fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1: (WRONG ONE) No errors included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "b, a, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "print(\" E = {:.1f}*ch + {:.1f}\".format(b,a))\n",
    "## not a clue on how to estimate the errors =(\n",
    "## I think std_err it is the error of the slope only, error for offset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2: (STILL WRONG) Errors only on the $y$ axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "def f(x, a, b):\n",
    "    \"a line\"\n",
    "    return a + b*x\n",
    "\n",
    "def ff(x, p):\n",
    "    \"helper function\"\n",
    "    return f(x, *p)\n",
    "\n",
    "# initial guesses\n",
    "a = 0\n",
    "b = 1\n",
    "\n",
    "pstart = [a,b]\n",
    "\n",
    "def fit_curvefit(p0, datax, datay, function, yerr=None, **kwargs):\n",
    "    \"Generic fitting function for when one has errors or not in the input data\"\n",
    "\n",
    "    if yerr is not None:\n",
    "        pfit, pcov = \\\n",
    "             optimize.curve_fit(f,datax,datay,p0=p0,\\\n",
    "                                sigma=yerr, epsfcn=0.0001, **kwargs)\n",
    "    else:\n",
    "        pfit, pcov = \\\n",
    "             optimize.curve_fit(f,datax,datay,p0=p0,\\\n",
    "                                epsfcn=0.0001, **kwargs)\n",
    "    error = [] \n",
    "    for i in range(len(pfit)):\n",
    "        try:\n",
    "          error.append(np.absolute(pcov[i][i])**0.5)\n",
    "        except:\n",
    "          error.append( 0.00 )\n",
    "    pfit_curvefit = pfit\n",
    "    perr_curvefit = np.array(error)\n",
    "    return pfit_curvefit, perr_curvefit \n",
    "\n",
    "##\n",
    "## Do the fit with the values only\n",
    "##\n",
    "pfit, perr = fit_curvefit(pstart, x, y, ff)\n",
    "\n",
    "print(\"\\n# Fit parameters and parameter errors from curve_fit method :\")\n",
    "print(\"pfit = \", pfit)\n",
    "print(\"perr = \", perr)\n",
    "a = ufloat(pfit[0],perr[0])\n",
    "b = ufloat(pfit[1],perr[1])\n",
    "print(\"a = {:S}\".format(a))\n",
    "print(\"b = {:S}\".format(b))\n",
    "\n",
    "ch = 227.3\n",
    "E = a + ch*b\n",
    "print(\"E @ {:.1f} = {:S}\".format(ch, E))\n",
    "\n",
    "##\n",
    "## Do the fit with the uncertainty only on the y axis\n",
    "##\n",
    "pfit, perr = fit_curvefit(pstart, x, y, ff, dy)\n",
    "\n",
    "print(\"\\n# Fit parameters and parameter errors from curve_fit method :\")\n",
    "print(\"pfit = \", pfit)\n",
    "print(\"perr = \", perr)\n",
    "a = ufloat(pfit[0],perr[0])\n",
    "b = ufloat(pfit[1],perr[1])\n",
    "print(\"a = {:S}\".format(a))\n",
    "print(\"b = {:S}\".format(b))\n",
    "\n",
    "E = a + ch*b\n",
    "print(\"E @ {:.1f} = {:S}\".format(ch,E))\n",
    "\n",
    "\n",
    "### Results with y-errors included\n",
    "# Fit parameters and parameter errors from curve_fit method :\n",
    "#pfit =  [-61.96861944   3.17793761]\n",
    "#perr =  [1.65069473 0.00342302]\n",
    "#a = -62.0(1.7)\n",
    "#b = 3.1779(34)\n",
    "#E = 660.4(1.8)\n",
    "\n",
    "## The unceirtainties are on x...\n",
    "#the results including unceirtanties in y are not suprisingly\n",
    "# basically IDENTICAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 3: (Now we are talking) error on both axes \n",
    "\n",
    "Unlike the previous example, we do not use the curve_fit module of Scipy, Instead, there is  another  dedicated module to estimate the orthogonal distance regression (odr). \n",
    "\n",
    "**Note that the uncertainties in the y axis are assumed to be the systematic ones only**\n",
    "\n",
    "The program with some comments is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pylab import *\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import odr\n",
    "\n",
    "def func(p, x):\n",
    "    \"function to fit\"\n",
    "    a, b = p\n",
    "    return a + b*x\n",
    "\n",
    "# Model object\n",
    "quad_model = odr.Model(func)\n",
    "\n",
    "# Create a RealData object\n",
    "data = odr.RealData(x, y, sx=dx, sy=dy)\n",
    "\n",
    "# Set up ODR with the model and data.\n",
    "odr = odr.ODR(data, quad_model, beta0=[0., 1.]) # initial guess of parameters\n",
    "\n",
    "# Run the regression.\n",
    "out = odr.run()\n",
    "\n",
    "#print fit parameters and 1-sigma estimates\n",
    "popt = out.beta\n",
    "perr = out.sd_beta\n",
    "print('fit parameter 1-sigma error')\n",
    "print('———————————–')\n",
    "for i in range(len(popt)):\n",
    "    print(\"{:6.2f} +/- {:6.2f}\".format(popt[i], perr[i]))\n",
    "print()\n",
    "    \n",
    "a = ufloat(popt[0],perr[0])\n",
    "b = ufloat(popt[1],perr[1])\n",
    "print(\"a = {:uS}\".format(a))\n",
    "print(\"b = {:uS}\".format(b))\n",
    "\n",
    "ch = ufloat_fromstr(\"227.3(8)\")\n",
    "E = a + ch*b\n",
    "print(\"E = {:uS}\".format(E))\n",
    "\n",
    "# prepare confidence level curves\n",
    "nstd = 5. # to draw 5-sigma intervals\n",
    "popt_up = popt + nstd * perr\n",
    "popt_dw = popt - nstd * perr\n",
    "\n",
    "x_fit = np.linspace(min(x), max(x), 100)\n",
    "fit = func(popt, x_fit)\n",
    "fit_up = func(popt_up, x_fit)\n",
    "fit_dw = func(popt_dw, x_fit)\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(1)\n",
    "rcParams['font.size']= 20\n",
    "xlabel('x', fontsize=16)\n",
    "ylabel('y', fontsize=16)\n",
    "title('fit with error on both axis', fontsize=18)\n",
    "## plot points with errors in both axes\n",
    "errorbar(x, y, yerr=dy, xerr=dx, ecolor='k', fmt='none', label='data')\n",
    "## plot line corresponding to fit\n",
    "plot(x_fit, fit, 'r', lw=0.5, label='best fit curve')\n",
    "## color a 5 sigma region to the fit \n",
    "ax.fill_between(x_fit, fit_up, fit_dw, alpha=.25, label='5-sigma interval')\n",
    "legend(loc='lower right',fontsize=16)\n",
    "show()\n",
    "## OBS: 5-sigma thickness is comparable/smaller with best fit sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
